{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35df77bf",
   "metadata": {},
   "source": [
    "# Wildfire Prediction\n",
    "\n",
    "This Jupyter Notebook implements various MLPs and CNNs to predict whether a landscape image represents a wildfire or not. PyTorch will be the main library used for this project. \n",
    "\n",
    "Image Specifications:\n",
    "- Type: `.jpg`\n",
    "- Dimensions: 250 x 250 pixels\n",
    "- Horizontal/vertical resolution: 96 dpi\n",
    "- Bit depth: 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d7ce618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "295785df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1a11aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train, validation, and test sets\n",
    "torch.manual_seed(42)\n",
    "\n",
    "train_validation_set = torchvision.datasets.ImageFolder('forest_fire/Training and Validation', transform)\n",
    "train_size = int(0.8 * len(train_validation_set))\n",
    "val_size = len(train_validation_set) - train_size\n",
    "\n",
    "train_set, val_set = random_split(train_validation_set, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size = 64,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size = 64, \n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.ImageFolder('forest_fire/Testing', transform)\n",
    "test_loader = DataLoader(\n",
    "    test_set,\n",
    "    batch_size = 64,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "597f19cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants\n",
    "input_size = 250 * 250 * 3\n",
    "classes = ['fire', 'nofire']\n",
    "num_classes = 2\n",
    "num_epochs = 20\n",
    "\n",
    "# Eight different MLP architectures to experiment\n",
    "mlp_hidden_sizes = [\n",
    "    [64],\n",
    "    [128, 64],\n",
    "    [256, 64],\n",
    "    [512, 128],\n",
    "    [256, 128, 64],\n",
    "    [1024, 256, 64],\n",
    "    [512, 256, 128, 64],\n",
    "    [1024, 512, 256, 128, 64]\n",
    "]\n",
    "\n",
    "# Nine different CNN architectures to experiment\n",
    "conv_sizes = [3, 5, 7]\n",
    "cnn_hidden_sizes = [\n",
    "    [32],\n",
    "    [32, 64],\n",
    "    [32, 64, 128]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "335dab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dynamic Multi-layer Perceptron\n",
    "class DynamicMLP(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_sizes, num_classes):\n",
    "        super(DynamicMLP, self).__init__()\n",
    "        layers = [nn.Flatten()]\n",
    "\n",
    "        # Construct MLP\n",
    "        prev_size = input_size\n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev_size = hidden_size\n",
    "\n",
    "        # Make output layer\n",
    "        layers.append(nn.Linear(prev_size, num_classes))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2a0dcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dynamic Convolutional Neural Network\n",
    "class DynamicCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_sizes, conv_size, num_classes):\n",
    "        super(DynamicCNN, self).__init__()\n",
    "        layers = []\n",
    "\n",
    "        # Construct CNN\n",
    "        curr_layer = 3 # initially RGB channels\n",
    "        img_dim = 250 # image dimension\n",
    "        for hidden_size in hidden_sizes:\n",
    "            padding = conv_size // 2\n",
    "            layers.append(nn.Conv2d(curr_layer, hidden_size, kernel_size=conv_size, padding=padding))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.MaxPool2d(2))\n",
    "            img_dim = img_dim // 2\n",
    "            curr_layer = hidden_size\n",
    "\n",
    "        # Output layer\n",
    "        # print(img_dim * img_dim * curr_layer)\n",
    "        layers.append(nn.Flatten())\n",
    "        layers.append(nn.Linear(img_dim * img_dim * curr_layer, num_classes))\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77118189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation loop\n",
    "def train_loop(train_model, train_loader, val_loader, num_epochs, model_num):\n",
    "\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    model = train_model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    epoch_nums = np.arange(1, 21)\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    if type(train_model) == DynamicMLP:\n",
    "        file_name = f\"mlp_results/mlp{model_num}_results_log.txt\"\n",
    "    else:\n",
    "        file_name = f\"mlp_results/mlp{model_num}_results_log.txt\"\n",
    "\n",
    "    with open(file_name, 'w') as f:\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            # TRAINING\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            for inputs, labels in train_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            train_loss = running_loss / len(train_loader)\n",
    "            train_accuracy = 100 * correct / total\n",
    "            train_accuracies.append(train_accuracy)\n",
    "\n",
    "            # VALIDATION\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in val_loader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    val_loss += loss.item()\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "            val_accuracy = 100 * val_correct / val_total\n",
    "            val_accuracies.append(val_accuracy)\n",
    "\n",
    "            epoch_str = f\"Epoch [{epoch+1}/{num_epochs}]\"\n",
    "            train_str = f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\"\n",
    "            val_str = f\"Validation Loss: {train_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\\n\"\n",
    "\n",
    "            print(epoch_str)\n",
    "            print(train_str)\n",
    "            print(val_str)\n",
    "\n",
    "            f.write(epoch_str +'\\n')\n",
    "            f.write(train_str + '\\n')\n",
    "            f.write(val_str + '\\n')\n",
    "\n",
    "    plt.plot(epoch_nums, train_accuracies)\n",
    "    plt.xticks(np.arange(1, 21))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Train Accuracy')\n",
    "    plt.title('Train Accuracy vs. Epoch Line Graph')\n",
    "    plt.show()\n",
    "\n",
    "    if type(model) == DynamicMLP:\n",
    "        plt.savefig(f\"mlp_results/mlp{model_num}_train_acc_plot.png\")\n",
    "    else:\n",
    "        plt.savefig(f\"cnn_results/cnn{model_num}_train_acc_plot.png\")\n",
    "\n",
    "    plt.plot(epoch_nums, val_accuracies)\n",
    "    plt.xticks(np.arange(1, 21))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.title('Validation Accuracy vs. Epoch Line Graph')\n",
    "    plt.show()\n",
    "    plt.savefig('')\n",
    "\n",
    "    if type(model) == DynamicMLP:\n",
    "        plt.savefig(f\"mlp_results/mlp{model_num}_validation_acc_plot.png\")\n",
    "    else:\n",
    "        plt.savefig(f\"cnn_results/cnn{model_num}_validation_acc_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21899d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing loop\n",
    "def test_loop(model, test_loader, model_num):\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_loss = running_loss / len(test_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    if type(model) == DynamicMLP:\n",
    "        file_name = f\"mlp_results/mlp{model_num}_results_log.txt\"\n",
    "    else:\n",
    "        file_name = f\"cnn_results/mlp{model_num}_results_log.txt\"\n",
    "\n",
    "    with open(file_name, 'a') as f:\n",
    "        test_str = f\"Test Loss: {avg_loss:4f}, Test Accuracy: {accuracy:2f}%\"\n",
    "        print(test_str)\n",
    "        f.write(test_str + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d78f65a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_process(model, train_loader, val_loader, test_loader, num_epochs, model_num):\n",
    "    train_loop(model, train_loader, val_loader, num_epochs, model_num)\n",
    "    test_loop(model, test_loader, model_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc3ffcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the MLPs\n",
    "mlp_1 = DynamicMLP(input_size, mlp_hidden_sizes[0], num_classes)\n",
    "mlp_2 = DynamicMLP(input_size, mlp_hidden_sizes[1], num_classes)\n",
    "mlp_3 = DynamicMLP(input_size, mlp_hidden_sizes[2], num_classes)\n",
    "mlp_4 = DynamicMLP(input_size, mlp_hidden_sizes[3], num_classes)\n",
    "mlp_5 = DynamicMLP(input_size, mlp_hidden_sizes[4], num_classes)\n",
    "mlp_6 = DynamicMLP(input_size, mlp_hidden_sizes[5], num_classes)\n",
    "mlp_7 = DynamicMLP(input_size, mlp_hidden_sizes[6], num_classes)\n",
    "mlp_8 = DynamicMLP(input_size, mlp_hidden_sizes[7], num_classes)\n",
    "mlps = [mlp_1, mlp_2, mlp_3, mlp_4, mlp_5, mlp_6, mlp_7, mlp_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69f94b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CNNs\n",
    "\n",
    "# Architecture 1\n",
    "cnn_1 = DynamicCNN(cnn_hidden_sizes[0], conv_sizes[0], num_classes)\n",
    "cnn_2 = DynamicCNN(cnn_hidden_sizes[0], conv_sizes[1], num_classes)\n",
    "cnn_3 = DynamicCNN(cnn_hidden_sizes[0], conv_sizes[2], num_classes)\n",
    "\n",
    "# Architecture 2\n",
    "cnn_4 = DynamicCNN(cnn_hidden_sizes[1], conv_sizes[0], num_classes)\n",
    "cnn_5 = DynamicCNN(cnn_hidden_sizes[1], conv_sizes[1], num_classes)\n",
    "cnn_6 = DynamicCNN(cnn_hidden_sizes[1], conv_sizes[2], num_classes)\n",
    "\n",
    "# Architecture 3\n",
    "cnn_7 = DynamicCNN(cnn_hidden_sizes[2], conv_sizes[0], num_classes)\n",
    "cnn_8 = DynamicCNN(cnn_hidden_sizes[2], conv_sizes[1], num_classes)\n",
    "cnn_9 = DynamicCNN(cnn_hidden_sizes[2], conv_sizes[2], num_classes)\n",
    "\n",
    "cnns = [cnn_1, cnn_2, cnn_3, cnn_4, cnn_5, cnn_6, cnn_7, cnn_8, cnn_9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39e52b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to train, validate, and test all MLPs (last run took 25 minutes)\n",
    "for i in range(8):\n",
    "    print(f'Now running MLP #{i+1}...')\n",
    "    run_process(mlps[i], train_loader, val_loader, test_loader, num_epochs, i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e8def6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to train, validate, and test all CNNs\n",
    "for i in range(9):\n",
    "    print(f'Now running CNN #{i+1}...')\n",
    "    run_process(cnns[i], train_loader, val_loader, test_loader, num_epochs, i + 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

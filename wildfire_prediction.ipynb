{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35df77bf",
   "metadata": {},
   "source": [
    "# Wildfire Prediction\n",
    "\n",
    "This Jupyter Notebook implements various MLPs and CNNs to predict whether a landscape image represents a wildfire or not. PyTorch will be the main library used for this project. \n",
    "\n",
    "Image Specifications:\n",
    "- Type: `.jpg`\n",
    "- Dimensions: 250 x 250 pixels\n",
    "- Horizontal/vertical resolution: 96 dpi\n",
    "- Bit depth: 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d7ce618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "295785df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1a11aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_set = torchvision.datasets.ImageFolder('forest_fire/Training and Validation', transform)\n",
    "trainloader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size = 64,\n",
    "    shuffle = True\n",
    ")\n",
    "test_set = torchvision.datasets.ImageFolder('forest_fire/Testing', transform)\n",
    "testloader = DataLoader(\n",
    "    test_set,\n",
    "    batch_size = 64,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "597f19cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants\n",
    "input_size = 250 * 250 * 3\n",
    "classes = ['fire', 'nofire']\n",
    "num_classes = 2\n",
    "num_epochs = 20\n",
    "\n",
    "# Eight different MLP architectures to experiment\n",
    "mlp_hidden_sizes = [\n",
    "    [64],\n",
    "    [128, 64],\n",
    "    [256, 64],\n",
    "    [512, 128],\n",
    "    [256, 128, 64],\n",
    "    [1024, 256, 64],\n",
    "    [512, 256, 128, 64],\n",
    "    [1024, 512, 256, 128, 64]\n",
    "]\n",
    "\n",
    "# Nine different CNN architectures to experiment\n",
    "conv_sizes = [3, 5, 7]\n",
    "cnn_hidden_sizes = [\n",
    "    [32],\n",
    "    [32, 64],\n",
    "    [32, 64, 128]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "335dab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dynamic Multi-layer Perceptron\n",
    "class DynamicMLP(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_sizes, num_classes):\n",
    "        super(DynamicMLP, self).__init__()\n",
    "        layers = [nn.Flatten()]\n",
    "\n",
    "        # Construct MLP\n",
    "        prev_size = input_size\n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev_size = hidden_size\n",
    "\n",
    "        # Make output layer\n",
    "        layers.append(nn.Linear(prev_size, num_classes))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2a0dcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dynamic Convolutional Neural Network\n",
    "class DynamicCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_sizes, conv_size, num_classes):\n",
    "        super(DynamicCNN, self).__init__()\n",
    "        layers = []\n",
    "\n",
    "        # Construct CNN\n",
    "        curr_layer = 3 # initially RGB channels\n",
    "        img_dim = 250 # image dimension\n",
    "        for hidden_size in hidden_sizes:\n",
    "            padding = conv_size // 2\n",
    "            layers.append(nn.Conv2d(curr_layer, hidden_size, kernel_size=conv_size, padding=padding))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.MaxPool2d(2))\n",
    "            img_dim = img_dim // 2\n",
    "            curr_layer = hidden_size\n",
    "\n",
    "        # Output layer\n",
    "        # print(img_dim * img_dim * curr_layer)\n",
    "        layers.append(nn.Flatten())\n",
    "        layers.append(nn.Linear(img_dim * img_dim * curr_layer, num_classes))\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77118189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_loop(train_model, trainloader, num_epochs):\n",
    "\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    model = train_model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        avg_loss = running_loss / len(trainloader)\n",
    "        accuracy = 100 * correct / total\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc3ffcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the MLPs\n",
    "mlp_1 = DynamicMLP(input_size, mlp_hidden_sizes[0], num_classes)\n",
    "mlp_2 = DynamicMLP(input_size, mlp_hidden_sizes[1], num_classes)\n",
    "mlp_3 = DynamicMLP(input_size, mlp_hidden_sizes[2], num_classes)\n",
    "mlp_4 = DynamicMLP(input_size, mlp_hidden_sizes[3], num_classes)\n",
    "mlp_5 = DynamicMLP(input_size, mlp_hidden_sizes[4], num_classes)\n",
    "mlp_6 = DynamicMLP(input_size, mlp_hidden_sizes[5], num_classes)\n",
    "mlp_7 = DynamicMLP(input_size, mlp_hidden_sizes[6], num_classes)\n",
    "mlp_8 = DynamicMLP(input_size, mlp_hidden_sizes[7], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05f34108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 3.5251, Accuracy: 84.01%\n",
      "Epoch [2/20], Loss: 1.3195, Accuracy: 91.65%\n",
      "Epoch [3/20], Loss: 0.4122, Accuracy: 95.14%\n",
      "Epoch [4/20], Loss: 0.2582, Accuracy: 95.91%\n",
      "Epoch [5/20], Loss: 0.1289, Accuracy: 97.60%\n",
      "Epoch [6/20], Loss: 0.1001, Accuracy: 97.54%\n",
      "Epoch [7/20], Loss: 0.0882, Accuracy: 97.49%\n",
      "Epoch [8/20], Loss: 0.0348, Accuracy: 98.96%\n",
      "Epoch [9/20], Loss: 0.0834, Accuracy: 98.36%\n",
      "Epoch [10/20], Loss: 0.0388, Accuracy: 98.74%\n",
      "Epoch [11/20], Loss: 0.0765, Accuracy: 97.93%\n",
      "Epoch [12/20], Loss: 0.0242, Accuracy: 99.02%\n",
      "Epoch [13/20], Loss: 0.0797, Accuracy: 97.05%\n",
      "Epoch [14/20], Loss: 0.0725, Accuracy: 97.76%\n",
      "Epoch [15/20], Loss: 0.0293, Accuracy: 99.18%\n",
      "Epoch [16/20], Loss: 0.0143, Accuracy: 99.56%\n",
      "Epoch [17/20], Loss: 0.0180, Accuracy: 99.51%\n",
      "Epoch [18/20], Loss: 0.0154, Accuracy: 99.56%\n",
      "Epoch [19/20], Loss: 0.0096, Accuracy: 99.73%\n",
      "Epoch [20/20], Loss: 0.0184, Accuracy: 99.51%\n"
     ]
    }
   ],
   "source": [
    "train_loop(mlp_1, trainloader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ab4a3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.1893, Accuracy: 83.52%\n",
      "Epoch [2/20], Loss: 0.3106, Accuracy: 92.14%\n",
      "Epoch [3/20], Loss: 0.1643, Accuracy: 94.76%\n",
      "Epoch [4/20], Loss: 0.1222, Accuracy: 96.40%\n",
      "Epoch [5/20], Loss: 0.0790, Accuracy: 97.76%\n",
      "Epoch [6/20], Loss: 0.0816, Accuracy: 97.49%\n",
      "Epoch [7/20], Loss: 0.0666, Accuracy: 97.54%\n",
      "Epoch [8/20], Loss: 0.0546, Accuracy: 98.20%\n",
      "Epoch [9/20], Loss: 0.0294, Accuracy: 99.02%\n",
      "Epoch [10/20], Loss: 0.0190, Accuracy: 99.73%\n",
      "Epoch [11/20], Loss: 0.0209, Accuracy: 99.45%\n",
      "Epoch [12/20], Loss: 0.0140, Accuracy: 99.56%\n",
      "Epoch [13/20], Loss: 0.0083, Accuracy: 99.89%\n",
      "Epoch [14/20], Loss: 0.0074, Accuracy: 99.78%\n",
      "Epoch [15/20], Loss: 0.0288, Accuracy: 98.91%\n",
      "Epoch [16/20], Loss: 0.0163, Accuracy: 99.51%\n",
      "Epoch [17/20], Loss: 0.0385, Accuracy: 98.96%\n",
      "Epoch [18/20], Loss: 0.1352, Accuracy: 96.89%\n",
      "Epoch [19/20], Loss: 0.1827, Accuracy: 96.12%\n",
      "Epoch [20/20], Loss: 0.1401, Accuracy: 96.78%\n"
     ]
    }
   ],
   "source": [
    "train_loop(mlp_2, trainloader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "450d9fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.5434, Accuracy: 82.91%\n",
      "Epoch [2/20], Loss: 0.4562, Accuracy: 91.98%\n",
      "Epoch [3/20], Loss: 0.1631, Accuracy: 94.87%\n",
      "Epoch [4/20], Loss: 0.1344, Accuracy: 96.23%\n",
      "Epoch [5/20], Loss: 0.1329, Accuracy: 97.11%\n",
      "Epoch [6/20], Loss: 0.0706, Accuracy: 97.82%\n",
      "Epoch [7/20], Loss: 0.0374, Accuracy: 99.02%\n",
      "Epoch [8/20], Loss: 0.0551, Accuracy: 98.25%\n",
      "Epoch [9/20], Loss: 0.0919, Accuracy: 97.16%\n",
      "Epoch [10/20], Loss: 0.0785, Accuracy: 97.65%\n",
      "Epoch [11/20], Loss: 0.1148, Accuracy: 96.78%\n",
      "Epoch [12/20], Loss: 0.0443, Accuracy: 98.69%\n",
      "Epoch [13/20], Loss: 0.0253, Accuracy: 99.24%\n",
      "Epoch [14/20], Loss: 0.0299, Accuracy: 99.29%\n",
      "Epoch [15/20], Loss: 0.0132, Accuracy: 99.78%\n",
      "Epoch [16/20], Loss: 0.0064, Accuracy: 99.95%\n",
      "Epoch [17/20], Loss: 0.0106, Accuracy: 99.67%\n",
      "Epoch [18/20], Loss: 0.0078, Accuracy: 99.84%\n",
      "Epoch [19/20], Loss: 0.0074, Accuracy: 99.95%\n",
      "Epoch [20/20], Loss: 0.0024, Accuracy: 99.95%\n"
     ]
    }
   ],
   "source": [
    "train_loop(mlp_3, trainloader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fe6a914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 3.3105, Accuracy: 81.99%\n",
      "Epoch [2/20], Loss: 0.5806, Accuracy: 92.25%\n",
      "Epoch [3/20], Loss: 0.2708, Accuracy: 93.50%\n",
      "Epoch [4/20], Loss: 0.2578, Accuracy: 93.78%\n",
      "Epoch [5/20], Loss: 0.0964, Accuracy: 97.16%\n",
      "Epoch [6/20], Loss: 0.0716, Accuracy: 97.98%\n",
      "Epoch [7/20], Loss: 0.0746, Accuracy: 97.76%\n",
      "Epoch [8/20], Loss: 0.0881, Accuracy: 97.22%\n",
      "Epoch [9/20], Loss: 0.0514, Accuracy: 98.25%\n",
      "Epoch [10/20], Loss: 0.0292, Accuracy: 99.24%\n",
      "Epoch [11/20], Loss: 0.0159, Accuracy: 99.34%\n",
      "Epoch [12/20], Loss: 0.0168, Accuracy: 99.51%\n",
      "Epoch [13/20], Loss: 0.0167, Accuracy: 99.56%\n",
      "Epoch [14/20], Loss: 0.0045, Accuracy: 99.89%\n",
      "Epoch [15/20], Loss: 0.0036, Accuracy: 99.95%\n",
      "Epoch [16/20], Loss: 0.0021, Accuracy: 100.00%\n",
      "Epoch [17/20], Loss: 0.0011, Accuracy: 100.00%\n",
      "Epoch [18/20], Loss: 0.0010, Accuracy: 100.00%\n",
      "Epoch [19/20], Loss: 0.0008, Accuracy: 100.00%\n",
      "Epoch [20/20], Loss: 0.0007, Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "train_loop(mlp_4, trainloader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5da76de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.6663, Accuracy: 83.68%\n",
      "Epoch [2/20], Loss: 0.2004, Accuracy: 92.85%\n",
      "Epoch [3/20], Loss: 0.1609, Accuracy: 94.71%\n",
      "Epoch [4/20], Loss: 0.1248, Accuracy: 96.07%\n",
      "Epoch [5/20], Loss: 0.1409, Accuracy: 95.41%\n",
      "Epoch [6/20], Loss: 0.1678, Accuracy: 95.69%\n",
      "Epoch [7/20], Loss: 0.1039, Accuracy: 97.33%\n",
      "Epoch [8/20], Loss: 0.0512, Accuracy: 98.74%\n",
      "Epoch [9/20], Loss: 0.0323, Accuracy: 99.18%\n",
      "Epoch [10/20], Loss: 0.0286, Accuracy: 99.02%\n",
      "Epoch [11/20], Loss: 0.0210, Accuracy: 99.51%\n",
      "Epoch [12/20], Loss: 0.0154, Accuracy: 99.45%\n",
      "Epoch [13/20], Loss: 0.0147, Accuracy: 99.73%\n",
      "Epoch [14/20], Loss: 0.0228, Accuracy: 99.40%\n",
      "Epoch [15/20], Loss: 0.0585, Accuracy: 98.31%\n",
      "Epoch [16/20], Loss: 0.0730, Accuracy: 97.43%\n",
      "Epoch [17/20], Loss: 0.0890, Accuracy: 97.71%\n",
      "Epoch [18/20], Loss: 0.0761, Accuracy: 97.43%\n",
      "Epoch [19/20], Loss: 0.0345, Accuracy: 98.64%\n",
      "Epoch [20/20], Loss: 0.0197, Accuracy: 99.24%\n"
     ]
    }
   ],
   "source": [
    "train_loop(mlp_5, trainloader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "521b5a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.5800, Accuracy: 79.31%\n",
      "Epoch [2/20], Loss: 0.2579, Accuracy: 91.38%\n",
      "Epoch [3/20], Loss: 0.2030, Accuracy: 93.29%\n",
      "Epoch [4/20], Loss: 0.1689, Accuracy: 94.81%\n",
      "Epoch [5/20], Loss: 0.1867, Accuracy: 93.29%\n",
      "Epoch [6/20], Loss: 0.0867, Accuracy: 97.65%\n",
      "Epoch [7/20], Loss: 0.0533, Accuracy: 98.96%\n",
      "Epoch [8/20], Loss: 0.0583, Accuracy: 98.58%\n",
      "Epoch [9/20], Loss: 0.0643, Accuracy: 97.98%\n",
      "Epoch [10/20], Loss: 0.0590, Accuracy: 98.31%\n",
      "Epoch [11/20], Loss: 0.0414, Accuracy: 98.58%\n",
      "Epoch [12/20], Loss: 0.0202, Accuracy: 99.62%\n",
      "Epoch [13/20], Loss: 0.0087, Accuracy: 99.89%\n",
      "Epoch [14/20], Loss: 0.0044, Accuracy: 99.95%\n",
      "Epoch [15/20], Loss: 0.0031, Accuracy: 99.95%\n",
      "Epoch [16/20], Loss: 0.0032, Accuracy: 99.95%\n",
      "Epoch [17/20], Loss: 0.0025, Accuracy: 100.00%\n",
      "Epoch [18/20], Loss: 0.0147, Accuracy: 99.51%\n",
      "Epoch [19/20], Loss: 0.0988, Accuracy: 97.76%\n",
      "Epoch [20/20], Loss: 0.0453, Accuracy: 98.74%\n"
     ]
    }
   ],
   "source": [
    "train_loop(mlp_6, trainloader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d2ddd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.7929, Accuracy: 79.97%\n",
      "Epoch [2/20], Loss: 0.2292, Accuracy: 91.48%\n",
      "Epoch [3/20], Loss: 0.1662, Accuracy: 94.05%\n",
      "Epoch [4/20], Loss: 0.1729, Accuracy: 94.38%\n",
      "Epoch [5/20], Loss: 0.1131, Accuracy: 96.07%\n",
      "Epoch [6/20], Loss: 0.0842, Accuracy: 97.22%\n",
      "Epoch [7/20], Loss: 0.0627, Accuracy: 97.82%\n",
      "Epoch [8/20], Loss: 0.0750, Accuracy: 97.93%\n",
      "Epoch [9/20], Loss: 0.0446, Accuracy: 98.74%\n",
      "Epoch [10/20], Loss: 0.0407, Accuracy: 98.85%\n",
      "Epoch [11/20], Loss: 0.0617, Accuracy: 98.14%\n",
      "Epoch [12/20], Loss: 0.0501, Accuracy: 98.42%\n",
      "Epoch [13/20], Loss: 0.0356, Accuracy: 98.91%\n",
      "Epoch [14/20], Loss: 0.0180, Accuracy: 99.56%\n",
      "Epoch [15/20], Loss: 0.0042, Accuracy: 99.89%\n",
      "Epoch [16/20], Loss: 0.1624, Accuracy: 94.71%\n",
      "Epoch [17/20], Loss: 0.1361, Accuracy: 97.05%\n",
      "Epoch [18/20], Loss: 0.0860, Accuracy: 98.14%\n",
      "Epoch [19/20], Loss: 0.0442, Accuracy: 98.36%\n",
      "Epoch [20/20], Loss: 0.0260, Accuracy: 99.18%\n"
     ]
    }
   ],
   "source": [
    "train_loop(mlp_7, trainloader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45da1878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.5094, Accuracy: 80.35%\n",
      "Epoch [2/20], Loss: 0.2363, Accuracy: 90.61%\n",
      "Epoch [3/20], Loss: 0.1679, Accuracy: 93.67%\n",
      "Epoch [4/20], Loss: 0.1350, Accuracy: 95.20%\n",
      "Epoch [5/20], Loss: 0.1482, Accuracy: 94.98%\n",
      "Epoch [6/20], Loss: 0.0894, Accuracy: 97.00%\n",
      "Epoch [7/20], Loss: 0.1540, Accuracy: 95.31%\n",
      "Epoch [8/20], Loss: 0.0998, Accuracy: 96.56%\n",
      "Epoch [9/20], Loss: 0.0766, Accuracy: 97.60%\n",
      "Epoch [10/20], Loss: 0.1085, Accuracy: 95.58%\n",
      "Epoch [11/20], Loss: 0.0715, Accuracy: 97.71%\n",
      "Epoch [12/20], Loss: 0.0510, Accuracy: 98.31%\n",
      "Epoch [13/20], Loss: 0.0413, Accuracy: 98.42%\n",
      "Epoch [14/20], Loss: 0.0925, Accuracy: 98.53%\n",
      "Epoch [15/20], Loss: 0.2039, Accuracy: 94.05%\n",
      "Epoch [16/20], Loss: 0.1402, Accuracy: 96.40%\n",
      "Epoch [17/20], Loss: 0.1088, Accuracy: 98.25%\n",
      "Epoch [18/20], Loss: 0.1035, Accuracy: 98.42%\n",
      "Epoch [19/20], Loss: 0.0559, Accuracy: 98.31%\n",
      "Epoch [20/20], Loss: 0.0505, Accuracy: 99.13%\n"
     ]
    }
   ],
   "source": [
    "train_loop(mlp_8, trainloader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69f94b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CNNs\n",
    "\n",
    "# Architecture 1\n",
    "cnn_1 = DynamicCNN(cnn_hidden_sizes[0], conv_sizes[0], num_classes)\n",
    "cnn_2 = DynamicCNN(cnn_hidden_sizes[0], conv_sizes[1], num_classes)\n",
    "cnn_3 = DynamicCNN(cnn_hidden_sizes[0], conv_sizes[2], num_classes)\n",
    "\n",
    "# Architecture 2\n",
    "cnn_4 = DynamicCNN(cnn_hidden_sizes[1], conv_sizes[0], num_classes)\n",
    "cnn_5 = DynamicCNN(cnn_hidden_sizes[1], conv_sizes[1], num_classes)\n",
    "cnn_6 = DynamicCNN(cnn_hidden_sizes[1], conv_sizes[2], num_classes)\n",
    "\n",
    "# Architecture 3\n",
    "cnn_7 = DynamicCNN(cnn_hidden_sizes[2], conv_sizes[0], num_classes)\n",
    "cnn_8 = DynamicCNN(cnn_hidden_sizes[2], conv_sizes[1], num_classes)\n",
    "cnn_9 = DynamicCNN(cnn_hidden_sizes[2], conv_sizes[2], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8678b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop(cnn_1, trainloader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805e97ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop(cnn_2, trainloader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bf682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop(cnn_3, trainloader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fd5b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop(cnn_4, trainloader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1cb5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop(cnn_5, trainloader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c120480",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop(cnn_6, trainloader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2340c0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop(cnn_7, trainloader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b095527",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop(cnn_8, trainloader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b57da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop(cnn_9, trainloader, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
